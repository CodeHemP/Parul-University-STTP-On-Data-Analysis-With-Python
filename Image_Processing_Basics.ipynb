{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture-1. Image Processing Basics Practise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOkzU86T7WusSImkGblFmeY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishpatel26/Ganpat-University-Data-Science/blob/main/Lecture_1_Image_Processing_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL55g7iJVMOP"
      },
      "source": [
        "## **What is Image?**\n",
        "\n",
        "![](https://www.kdnuggets.com/wp-content/uploads/image-data-analysis.jpg)\n",
        "\n",
        "## **What is Pixel?**\n",
        "\n",
        "* Computer store images as a mosaic of tiny squares which is known as **pixels**.\n",
        "* Pixel is known as : ***Pi* cture** **X** ***El* ements**\n",
        "* A simple way to describe each pixel is using a **combination of three colors**, namely ***Red, Green, Blue.*** This is what we call an ***RGB image.***\n",
        "* Each pixel is represented by three **8 bit numbers** associated to the values for **Red, Green, Blue** respectively. \n",
        "* Every color channel has range from **0 to 255**.\n",
        "* Every pixel contains 8 bits means $2^8 = 256$ ranges which is start from $0 \\text{ to } 255$\n",
        "![](https://www.kdnuggets.com/wp-content/uploads/green-rgb.png)\n",
        "\n",
        "* Combination of these three color will possess tends to the highest value among them. Since each value can have **256 different intensity or brightness value, it makes 16.8 million total shades.**\n",
        "\n",
        "## **256 Color Shades**\n",
        "\n",
        "![](https://qph.fs.quoracdn.net/main-qimg-deb7ca842460d73333326ef10b5dd551)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMX1vOBScHx9"
      },
      "source": [
        "### Downloading the image from internet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEFzjYL7c8HQ"
      },
      "source": [
        "**Machu Picchu** is a 15th-century Inca citadel, located in the ***Eastern Cordillera of southern Peru, on a 2,430-metre (7,970 ft) mountain ridge.***\n",
        "* It is located in the Machupicchu District within Urubamba Province above the Sacred Valley, which is 80 kilometres (50 mi) northwest of Cuzco. \n",
        "* The Urubamba River flows past it, cutting through the Cordillera and creating a canyon with a tropical mountain climate.  \n",
        "![](https://upload.wikimedia.org/wikipedia/commons/b/b8/Peru_physical_map.svg) ![](https://upload.wikimedia.org/wikipedia/commons/e/eb/Machu_Picchu%2C_Peru.jpg)\n",
        "\n",
        "> Source : https://en.wikipedia.org/wiki/Machu_Picchu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gC8ZizYUyu4",
        "outputId": "5018324b-93f4-4da3-ff74-a9280415876d"
      },
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/commons/e/eb/Machu_Picchu%2C_Peru.jpg"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-02 06:43:30--  https://upload.wikimedia.org/wikipedia/commons/e/eb/Machu_Picchu%2C_Peru.jpg\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 198.35.26.112, 2620:0:863:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|198.35.26.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 832888 (813K) [image/jpeg]\n",
            "Saving to: ‘Machu_Picchu,_Peru.jpg.2’\n",
            "\n",
            "Machu_Picchu,_Peru. 100%[===================>] 813.37K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-04-02 06:43:31 (7.28 MB/s) - ‘Machu_Picchu,_Peru.jpg.2’ saved [832888/832888]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt6DAoemcQV6"
      },
      "source": [
        "### Load Require Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmMfHTZScEhl"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DpJ_DdUcbVe"
      },
      "source": [
        "### Read Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px1J1OubcYlr"
      },
      "source": [
        "# Reading the image using cv2\n",
        "image = cv2.imread('/content/Machu_Picchu,_Peru.jpg')\n",
        "\n",
        "# Display image\n",
        "cv2_imshow(image)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAgWUpUAfEbf"
      },
      "source": [
        "### Image Statistics\n",
        "\n",
        "* We can see \n",
        "  * Image type\n",
        "  * Height, Width, Color Channel(Dimensions)\n",
        "  * Size of the Image\n",
        "  * Min value of Image Pixel\n",
        "  * Max value of Image Pixel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYcOEYkEfD3O",
        "outputId": "c2149fe8-d799-45ec-98df-63935c06b602"
      },
      "source": [
        "# height, width and color channel\n",
        "print(\"Image Statistics:\")\n",
        "print(\"-------------------------------\")\n",
        "print(\"> Type of Image : \", type(image))\n",
        "print(\"> Height :\", image.shape[0],\"\\n> Width :\", image.shape[1],\"\\n> Color Channel(Dimensions):\", image.shape[2])\n",
        "print(\"> Size of Image : \", image.nbytes)\n",
        "print(\"> Min RGB Value in this image : \", np.min(image))\n",
        "print(\"> Max RGB Value in this image : \", np.max(image))\n",
        "print(\"-------------------------------\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Statistics:\n",
            "-------------------------------\n",
            "> Type of Image :  <class 'numpy.ndarray'>\n",
            "> Height : 1067 \n",
            "> Width : 1600 \n",
            "> Color Channel(Dimensions): 3\n",
            "> Size of Image :  5121600\n",
            "> Min RGB Value in this image :  0\n",
            "> Max RGB Value in this image :  255\n",
            "-------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AykGuGeNcTQJ"
      },
      "source": [
        "### **Exercise**\n",
        "\n",
        "* Read the Image and print image statistics.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihHZpQZndLHW"
      },
      "source": [
        "### Write your code here"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpsKlvMxeRzK"
      },
      "source": [
        "### **Check the Pixel at Perticular point X = 100 and Y = 100**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMHtWypgcjhL",
        "outputId": "bc8dbfdc-2bc2-4200-ad8e-8ed1fa3812c9"
      },
      "source": [
        "X = 100\n",
        "Y = 100\n",
        "\n",
        "print(\"Pixel value at Point X= 100 and Y = 100 :\", image[X,Y])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pixel value at Point X= 100 and Y = 100 : [148  88  34]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYoInElgcApj"
      },
      "source": [
        "### **Exercise**\n",
        "\n",
        "* Check the Pixel at Perticular point X = 250 and Y = 50\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBJUFqXqcNbX"
      },
      "source": [
        "### Write your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-AxN-aCkiwM"
      },
      "source": [
        "### **COLOR CHANNEL**\n",
        "\n",
        "![](https://www.researchgate.net/profile/Konstantinos-Plataniotis/publication/253269938/figure/fig1/AS:298149273980930@1448095734706/Color-image-representation-in-the-RGB-color-domain.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdi3ubYfpAOR"
      },
      "source": [
        "### **1. Decompose the Blue Color Channel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE-NfK7Be7A8"
      },
      "source": [
        "# Extract the color channel\n",
        "blue, green, red = cv2.split(image)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeoC2kGnokgB",
        "outputId": "a3bce92f-9824-4ce4-c0a0-cdb110944a4e"
      },
      "source": [
        "print(\"Blue shape : \", blue.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Blue shape :  (1067, 1600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mGlU2VskVC-"
      },
      "source": [
        "# Generate the Zero size Image with same shape of Origional Image\n",
        "zeros = np.zeros(blue.shape, dtype = np.uint8)\n",
        "\n",
        "# Generate the Blue color Image\n",
        "Blue_Image = cv2.merge((blue,zeros,zeros))\n",
        "\n",
        "# Display Image\n",
        "cv2_imshow(Blue_Image)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npMVRJwBh9DZ"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-AU_YOkh8Yw"
      },
      "source": [
        "#### Write your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umou-SyOpfEv"
      },
      "source": [
        "### **2. Decompose the Green Color Channel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlKEG4VrmrP2",
        "outputId": "6d6da557-2576-4241-9bb3-acb55e380f6b"
      },
      "source": [
        "print(\"Green shape : \", green.shape)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Green shape :  (1067, 1600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpQQc5armxzJ"
      },
      "source": [
        "# Generate the Zero size Image with same shape of Origional Image\n",
        "zeros = np.zeros(green.shape, dtype = np.uint8)\n",
        "\n",
        "# Generate the Green color Image\n",
        "Green_Image = cv2.merge((zeros,green,zeros))\n",
        "\n",
        "# Display Image\n",
        "cv2_imshow(Green_Image)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kIkdjqYjM_s"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJbe5dRzjPXY"
      },
      "source": [
        "#### Write your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4w8spVep2xQ"
      },
      "source": [
        "### **3. Decompose the Red Color Channel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DsDPZ8eptDr",
        "outputId": "1d830d1c-9224-4fc7-d505-cd5b717169f9"
      },
      "source": [
        "print(\"Red shape : \", red.shape)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Red shape :  (1067, 1600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0HSeLXpqCYT"
      },
      "source": [
        "# Generate the Zero size Image with same shape of Origional Image\n",
        "zeros = np.zeros(red.shape, dtype = np.uint8)\n",
        "\n",
        "# Generate the Red color Image\n",
        "Red_Image = cv2.merge((zeros,zeros,red))\n",
        "\n",
        "# Display Image\n",
        "cv2_imshow(Red_Image)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhqPc0M6jZCc"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc00NAvyjbqk"
      },
      "source": [
        "###Write your code"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMS2GegcrKSH"
      },
      "source": [
        "### **Combine Color Combination of Different Color Channel**\n",
        "\n",
        "  * Blue + Green = Cyan\n",
        "  * Blue + Red = Magenta\n",
        "  * Red + Green = Yellow\n",
        "  * Red + Green + Blue = RGB\n",
        "\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/RBG_color_wheel.svg/1229px-RBG_color_wheel.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUcaJGdisTdR"
      },
      "source": [
        "#### **1. Blue + Green**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-NiIKlhqIdn",
        "outputId": "23988d39-ecb6-4c00-f7bb-48a9c3d230d9"
      },
      "source": [
        "print(\"Blue shape : \", blue.shape)\n",
        "print(\"Green shape : \", green.shape)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Blue shape :  (1067, 1600)\n",
            "Green shape :  (1067, 1600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqvWP5YdsdWq"
      },
      "source": [
        "# Generate the Zero size Image with same shape of Origional Image\n",
        "zeros = np.zeros(blue.shape, dtype = np.uint8)\n",
        "\n",
        "# Generate the Blue + Green color Image\n",
        "BG_Image = cv2.merge((blue,green,zeros))\n",
        "\n",
        "# Display Image\n",
        "cv2_imshow(BG_Image)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXM7ZqeBjhqy"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBkYM2O1jk-8"
      },
      "source": [
        "###write your code here"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yloBxOTs6D2"
      },
      "source": [
        "#### **2. Blue + Red**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42drciG2smQ3",
        "outputId": "12c3e4d9-2c0c-46a4-c68d-4ea1fa5e2f48"
      },
      "source": [
        "print(\"Blue shape : \", blue.shape)\n",
        "print(\"Red shape : \", red.shape)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Blue shape :  (1067, 1600)\n",
            "Red shape :  (1067, 1600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-dGPz-ttDbv"
      },
      "source": [
        "# Generate the Zero size Image with same shape of Origional Image\n",
        "zeros = np.zeros(blue.shape, dtype = np.uint8)\n",
        "\n",
        "# Generate the Blue + Green color Image\n",
        "BR_Image = cv2.merge((blue,zeros,red))\n",
        "\n",
        "# Display Image\n",
        "cv2_imshow(BR_Image)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6t8bmcejwEk"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K89-9K0Jj0fp"
      },
      "source": [
        "### Write your code here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6tAs5tItdL4"
      },
      "source": [
        "#### **3. Green + Red**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNkshREXtJS9",
        "outputId": "fad012e0-9438-40c4-c42d-e3e1ca202ee3"
      },
      "source": [
        "print(\"Green shape : \", green.shape)\n",
        "print(\"Red shape : \", red.shape)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Green shape :  (1067, 1600)\n",
            "Red shape :  (1067, 1600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7m82yDyupVy"
      },
      "source": [
        "# Generate the Zero size Image with same shape of Origional Image\n",
        "zeros = np.zeros(green.shape, dtype = np.uint8)\n",
        "\n",
        "# Generate the Blue + Green color Image\n",
        "RG_Image = cv2.merge((zeros,green,red))\n",
        "\n",
        "# Display Image\n",
        "cv2_imshow(RG_Image)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnZ9NYmpkFg3"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSl_gnPEkJNd"
      },
      "source": [
        "### Write your code here."
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OysQW3sAvVCs"
      },
      "source": [
        "#### **4.Red + Green + Blue**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IngWECXOuxBT",
        "outputId": "d2fb8887-5077-4ed1-beee-337e68cc5bc2"
      },
      "source": [
        "print(\"Blue shape : \", blue.shape)\n",
        "print(\"Green shape : \", green.shape)\n",
        "print(\"Red shape : \", red.shape)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Blue shape :  (1067, 1600)\n",
            "Green shape :  (1067, 1600)\n",
            "Red shape :  (1067, 1600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJm_QwwqvJEu"
      },
      "source": [
        "# Generate the Zero size Image with same shape of Origional Image\n",
        "zeros = np.zeros(green.shape, dtype = np.uint8)\n",
        "\n",
        "# Generate the Blue + Green color Image\n",
        "RGB_Image = cv2.merge((blue,green,red))\n",
        "\n",
        "# Display Image\n",
        "cv2_imshow(RGB_Image)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCb4OnYnkVpx"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG-d0zeXkZCq"
      },
      "source": [
        "### Write your code here."
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AQEnznuMlkI"
      },
      "source": [
        "### Display Image with matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RP3jJbIvNJp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZJMDoUFMriu"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaO3l7uikgaQ"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze8nYr15ki8G"
      },
      "source": [
        "### Write your code here."
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwcB_jHcOIKu"
      },
      "source": [
        "### Preprocessing Operation use before Doing Deep learning on Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA6op-iuO2Fv"
      },
      "source": [
        "#### **1. Resize**\n",
        "\n",
        "![](https://media.geeksforgeeks.org/wp-content/uploads/20190326204952/scaling3.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0XRdiQaMykw",
        "outputId": "eb149720-9d60-46e9-a6d3-1f2f360b2cb2"
      },
      "source": [
        "img_224 = cv2.resize(image,(224,224),  interpolation = cv2.INTER_NEAREST)\n",
        "print(\"Original Image size \", image.shape)\n",
        "print(\"Resize Image size \", img_224.shape)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Image size  (1067, 1600, 3)\n",
            "Resize Image size  (224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH8FdWF7NoN3",
        "outputId": "f9bafd0c-2dc9-413b-8fe4-dbbb4bcfee32"
      },
      "source": [
        "# height, width and color channel\n",
        "print(\"Image Statistics:\")\n",
        "print(\"-------------------------------\")\n",
        "print(\"> Type of Image : \", type(img_224))\n",
        "print(\"> Height :\", img_224.shape[0],\"\\n> Width :\", img_224.shape[1],\"\\n> Color Channel(Dimensions):\", img_224.shape[2])\n",
        "print(\"> Size of Image : \", img_224.nbytes)\n",
        "print(\"> Min RGB Value in this image : \", np.min(img_224))\n",
        "print(\"> Max RGB Value in this image : \", np.max(img_224))\n",
        "print(\"-------------------------------\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Statistics:\n",
            "-------------------------------\n",
            "> Type of Image :  <class 'numpy.ndarray'>\n",
            "> Height : 224 \n",
            "> Width : 224 \n",
            "> Color Channel(Dimensions): 3\n",
            "> Size of Image :  150528\n",
            "> Min RGB Value in this image :  0\n",
            "> Max RGB Value in this image :  255\n",
            "-------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vakq80gFN0RC"
      },
      "source": [
        "plt.figure(figsize=(15,12))\n",
        "plt.subplot(121)\n",
        "cv2_imshow(image)  # Original Image\n",
        "plt.axis('off')\n",
        "plt.subplot(122)\n",
        "cv2_imshow(img_224)  # Resize Image\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDwpgCv0k0ro"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNAzb04nk3w8"
      },
      "source": [
        "### Write your code here."
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5pA4t1wS9jd"
      },
      "source": [
        "#### **2.Image Rotation**\n",
        "\n",
        "![](https://i7x7p5b7.stackpathcdn.com/codrops/wp-content/uploads/2014/12/rotate-example.jpg)\n",
        "* Images can be rotated to any degree clockwise or otherwise. We just need to define rotation matrix listing rotation point, degree of rotation and the scaling factor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jVQb11nSA1z"
      },
      "source": [
        "rows, cols = image.shape[:2]"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc1LY5h5SMJG",
        "outputId": "436e822a-ace7-48ee-ba86-15fa52ffbd64"
      },
      "source": [
        "help(cv2.getRotationMatrix2D)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on built-in function getRotationMatrix2D:\n",
            "\n",
            "getRotationMatrix2D(...)\n",
            "    getRotationMatrix2D(center, angle, scale) -> retval\n",
            "    .   @brief Calculates an affine matrix of 2D rotation.\n",
            "    .   \n",
            "    .   The function calculates the following matrix:\n",
            "    .   \n",
            "    .   \\f[\\begin{bmatrix} \\alpha &  \\beta & (1- \\alpha )  \\cdot \\texttt{center.x} -  \\beta \\cdot \\texttt{center.y} \\\\ - \\beta &  \\alpha &  \\beta \\cdot \\texttt{center.x} + (1- \\alpha )  \\cdot \\texttt{center.y} \\end{bmatrix}\\f]\n",
            "    .   \n",
            "    .   where\n",
            "    .   \n",
            "    .   \\f[\\begin{array}{l} \\alpha =  \\texttt{scale} \\cdot \\cos \\texttt{angle} , \\\\ \\beta =  \\texttt{scale} \\cdot \\sin \\texttt{angle} \\end{array}\\f]\n",
            "    .   \n",
            "    .   The transformation maps the rotation center to itself. If this is not the target, adjust the shift.\n",
            "    .   \n",
            "    .   @param center Center of the rotation in the source image.\n",
            "    .   @param angle Rotation angle in degrees. Positive values mean counter-clockwise rotation (the\n",
            "    .   coordinate origin is assumed to be the top-left corner).\n",
            "    .   @param scale Isotropic scale factor.\n",
            "    .   \n",
            "    .   @sa  getAffineTransform, warpAffine, transform\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar01vrxmPiP4"
      },
      "source": [
        "rotate = cv2.getRotationMatrix2D(center = (cols/2, rows/2), \n",
        "                                       angle = 45, \n",
        "                                       scale = 1)\n",
        "res = cv2.warpAffine(image, rotate, (cols, rows))\n",
        "plt.imshow(res)\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUCIXJyLlBoQ"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7i87zUmlEqE"
      },
      "source": [
        "### Write your code here"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8yqUqZGTHdw"
      },
      "source": [
        "#### **3.Image Translation**\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/0/01/Traslazione_OK.svg)\n",
        "* Translating an image means shifting it within a given frame of reference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ilxMdZuSfIc",
        "outputId": "2375b985-540e-4a57-dea4-a6309c13cad3"
      },
      "source": [
        "help(cv2.warpAffine)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on built-in function warpAffine:\n",
            "\n",
            "warpAffine(...)\n",
            "    warpAffine(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]]) -> dst\n",
            "    .   @brief Applies an affine transformation to an image.\n",
            "    .   \n",
            "    .   The function warpAffine transforms the source image using the specified matrix:\n",
            "    .   \n",
            "    .   \\f[\\texttt{dst} (x,y) =  \\texttt{src} ( \\texttt{M} _{11} x +  \\texttt{M} _{12} y +  \\texttt{M} _{13}, \\texttt{M} _{21} x +  \\texttt{M} _{22} y +  \\texttt{M} _{23})\\f]\n",
            "    .   \n",
            "    .   when the flag #WARP_INVERSE_MAP is set. Otherwise, the transformation is first inverted\n",
            "    .   with #invertAffineTransform and then put in the formula above instead of M. The function cannot\n",
            "    .   operate in-place.\n",
            "    .   \n",
            "    .   @param src input image.\n",
            "    .   @param dst output image that has the size dsize and the same type as src .\n",
            "    .   @param M \\f$2\\times 3\\f$ transformation matrix.\n",
            "    .   @param dsize size of the output image.\n",
            "    .   @param flags combination of interpolation methods (see #InterpolationFlags) and the optional\n",
            "    .   flag #WARP_INVERSE_MAP that means that M is the inverse transformation (\n",
            "    .   \\f$\\texttt{dst}\\rightarrow\\texttt{src}\\f$ ).\n",
            "    .   @param borderMode pixel extrapolation method (see #BorderTypes); when\n",
            "    .   borderMode=#BORDER_TRANSPARENT, it means that the pixels in the destination image corresponding to\n",
            "    .   the \"outliers\" in the source image are not modified by the function.\n",
            "    .   @param borderValue value used in case of a constant border; by default, it is 0.\n",
            "    .   \n",
            "    .   @sa  warpPerspective, resize, remap, getRectSubPix, transform\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am32oOgFTOmh"
      },
      "source": [
        "rows, cols = image.shape[:2]"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS8GG0qYVz8v"
      },
      "source": [
        "* Let's shift by (200, 100)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw0CqLmEVoW4"
      },
      "source": [
        "M = np.float32([[1, 0, 200], [0, 1, 100]])\n",
        "img_trans = cv2.warpAffine(image, M, (cols, rows))\n",
        "plt.imshow(img_trans)\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF8M_qTtlMVS"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZXCMG99lPYx"
      },
      "source": [
        "### Write your code here."
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBf_r1PlWHvu"
      },
      "source": [
        "#### **4.Edge Detection**\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/%C3%84%C3%A4retuvastuse_n%C3%A4ide.png/500px-%C3%84%C3%A4retuvastuse_n%C3%A4ide.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTncoDXxWQky",
        "outputId": "ddbbce7b-e715-4995-892f-7ac460af225a"
      },
      "source": [
        "help(cv2.Canny)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on built-in function Canny:\n",
            "\n",
            "Canny(...)\n",
            "    Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient]]]) -> edges\n",
            "    .   @brief Finds edges in an image using the Canny algorithm @cite Canny86 .\n",
            "    .   \n",
            "    .   The function finds edges in the input image and marks them in the output map edges using the\n",
            "    .   Canny algorithm. The smallest value between threshold1 and threshold2 is used for edge linking. The\n",
            "    .   largest value is used to find initial segments of strong edges. See\n",
            "    .   <http://en.wikipedia.org/wiki/Canny_edge_detector>\n",
            "    .   \n",
            "    .   @param image 8-bit input image.\n",
            "    .   @param edges output edge map; single channels 8-bit image, which has the same size as image .\n",
            "    .   @param threshold1 first threshold for the hysteresis procedure.\n",
            "    .   @param threshold2 second threshold for the hysteresis procedure.\n",
            "    .   @param apertureSize aperture size for the Sobel operator.\n",
            "    .   @param L2gradient a flag, indicating whether a more accurate \\f$L_2\\f$ norm\n",
            "    .   \\f$=\\sqrt{(dI/dx)^2 + (dI/dy)^2}\\f$ should be used to calculate the image gradient magnitude (\n",
            "    .   L2gradient=true ), or whether the default \\f$L_1\\f$ norm \\f$=|dI/dx|+|dI/dy|\\f$ is enough (\n",
            "    .   L2gradient=false ).\n",
            "    \n",
            "    \n",
            "    \n",
            "    Canny(dx, dy, threshold1, threshold2[, edges[, L2gradient]]) -> edges\n",
            "    .   \\overload\n",
            "    .   \n",
            "    .   Finds edges in an image using the Canny algorithm with custom image gradient.\n",
            "    .   \n",
            "    .   @param dx 16-bit x derivative of input image (CV_16SC1 or CV_16SC3).\n",
            "    .   @param dy 16-bit y derivative of input image (same type as dx).\n",
            "    .   @param edges output edge map; single channels 8-bit image, which has the same size as image .\n",
            "    .   @param threshold1 first threshold for the hysteresis procedure.\n",
            "    .   @param threshold2 second threshold for the hysteresis procedure.\n",
            "    .   @param L2gradient a flag, indicating whether a more accurate \\f$L_2\\f$ norm\n",
            "    .   \\f$=\\sqrt{(dI/dx)^2 + (dI/dy)^2}\\f$ should be used to calculate the image gradient magnitude (\n",
            "    .   L2gradient=true ), or whether the default \\f$L_1\\f$ norm \\f$=|dI/dx|+|dI/dy|\\f$ is enough (\n",
            "    .   L2gradient=false ).\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGXZvm3DV94u"
      },
      "source": [
        "edges = cv2.Canny(image, 100, 100)\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.imshow(edges)\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMgsOD26lYO6"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxfyuEdDlc7l"
      },
      "source": [
        "### Write your code here."
      ],
      "execution_count": 103,
      "outputs": []
    }
  ]
}